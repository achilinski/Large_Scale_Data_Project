{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025acb04-7299-4546-a46c-79e7924ce6d2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "MACHINE_EVENT_ADD = 0\n",
    "MACHINE_EVENT_REMOVE = 1\n",
    "MACHINE_EVENT_UPDATE = 2\n",
    "\n",
    "TASK_EVENT_SCHEDULE = 1\n",
    "TASK_EVENT_EVICT = 2\n",
    "TASK_EVENT_FAIL = 3\n",
    "TASK_EVENT_FINISH = 4\n",
    "TASK_EVENT_KILL = 5\n",
    "TASK_EVENT_LOST = 6\n",
    "\n",
    "TASK_TERMINATION_EVENTS = {2, 3, 4, 5, 6}\n",
    "\n",
    "print(\"OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14cc6b-7c08-42f5-b67b-f5e9b0208f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark context\n",
    "conf = SparkConf().setAppName(\"OvercommitmentAnalysis\")\n",
    "sc = SparkContext(conf=conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8974fce5-1e01-44fe-8311-a6423193a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# DEFINITIONS\n",
    "\n",
    "def parse_machine_event(line):\n",
    "    \"\"\"Parse machine_events: timestamp, machine_id, event_type, platform_id, cpu_capacity, memory_capacity\"\"\"\n",
    "    try:\n",
    "        fields = line.strip().split(',')\n",
    "        if len(fields) < 6:\n",
    "            return None\n",
    "        \n",
    "        timestamp = int(fields[0]) if fields[0] else 0\n",
    "        machine_id = int(fields[1]) if fields[1] else None\n",
    "        event_type = int(fields[2]) if fields[2] else None\n",
    "        cpu_capacity = float(fields[4]) if fields[4] else 0.0\n",
    "        memory_capacity = float(fields[5]) if fields[5] else 0.0\n",
    "        \n",
    "        if machine_id is None or event_type is None:\n",
    "            return None\n",
    "        \n",
    "        if event_type not in [0, 1, 2]:\n",
    "            return None\n",
    "            \n",
    "        return (machine_id, (timestamp, event_type, cpu_capacity, memory_capacity))\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_task_event(line):\n",
    "    \"\"\"Parse task_events: timestamp, missing_info, job_id, task_index, machine_id, event_type, ..., cpu_request, memory_request, ...\"\"\"\n",
    "    try:\n",
    "        fields = line.strip().split(',')\n",
    "        if len(fields) < 12:\n",
    "            return None\n",
    "        \n",
    "        timestamp = int(fields[0]) if fields[0] else 0\n",
    "        job_id = int(fields[2]) if fields[2] else None\n",
    "        task_index = int(fields[3]) if fields[3] else None\n",
    "        machine_id = int(fields[4]) if fields[4] else None\n",
    "        event_type = int(fields[5]) if fields[5] else None\n",
    "        cpu_request = float(fields[9]) if fields[9] else 0.0\n",
    "        memory_request = float(fields[10]) if fields[10] else 0.0\n",
    "        \n",
    "        if job_id is None or task_index is None or event_type is None:\n",
    "            return None\n",
    "        \n",
    "        if event_type > 8:\n",
    "            return None\n",
    "        \n",
    "        task_id = (job_id, task_index)\n",
    "        return (task_id, (timestamp, machine_id, event_type, cpu_request, memory_request))\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_latest_machine_capacity(events):\n",
    "    sorted_events = sorted(events, key=lambda x: x[0])\n",
    "    \n",
    "    cpu_capacity = 0.0\n",
    "    memory_capacity = 0.0\n",
    "    is_active = False\n",
    "\n",
    "    for timestamp, event_type, cpu, memory in sorted_events:\n",
    "        if event_type == MACHINE_EVENT_ADD:\n",
    "            is_active = True\n",
    "            if cpu > 0:\n",
    "                cpu_capacity = cpu\n",
    "            if memory > 0:\n",
    "                memory_capacity = memory\n",
    "        elif event_type == MACHINE_EVENT_REMOVE:\n",
    "            is_active = False\n",
    "        elif event_type == MACHINE_EVENT_UPDATE:\n",
    "            if cpu > 0:\n",
    "                cpu_capacity = cpu\n",
    "            if memory > 0:\n",
    "                memory_capacity = memory\n",
    "\n",
    "    return cpu_capacity, memory_capacity, is_active\n",
    "\n",
    "\n",
    "def compute_task_running_periods(task_id, events):\n",
    "    sorted_events = sorted(events, key=lambda x: x[0])\n",
    "\n",
    "    periods = []\n",
    "    current_start = None\n",
    "    current_machine = None\n",
    "    current_cpu = 0.0\n",
    "    current_memory = 0.0\n",
    "\n",
    "    for timestamp, machine_id, event_type, cpu_request, memory_request in sorted_events:\n",
    "        if event_type == TASK_EVENT_SCHEDULE:\n",
    "            if current_start is None:\n",
    "                current_start = timestamp\n",
    "                current_machine = machine_id\n",
    "                current_cpu = cpu_request\n",
    "                current_memory = memory_request\n",
    "        elif event_type in TASK_TERMINATION_EVENTS:\n",
    "            if current_start is not None:\n",
    "                periods.append((current_machine, current_start, timestamp, current_cpu, current_memory))\n",
    "                current_start = None\n",
    "                current_machine = None\n",
    "                current_cpu = 0.0\n",
    "                current_memory = 0.0\n",
    "\n",
    "    return periods\n",
    "\n",
    "\n",
    "def analyze_machine_overcommitment(machine_id, task_periods, machine_capacities):\n",
    "    if machine_id not in machine_capacities:\n",
    "        return (machine_id, 0, 0, {})\n",
    "\n",
    "    machine_cpu_capacity, machine_memory_capacity = machine_capacities[machine_id]\n",
    "\n",
    "    events = []\n",
    "    for start_time, end_time, cpu_req, memory_req in task_periods:\n",
    "        events.append((start_time, 'start', cpu_req, memory_req))\n",
    "        events.append((end_time, 'end', cpu_req, memory_req))\n",
    "\n",
    "    events.sort()\n",
    "\n",
    "    current_cpu = 0.0\n",
    "    current_memory = 0.0\n",
    "    overcommit_count = 0\n",
    "    total_snapshots = 0\n",
    "\n",
    "    for timestamp, event_type, cpu_req, memory_req in events:\n",
    "        if event_type == 'start':\n",
    "            current_cpu += cpu_req\n",
    "            current_memory += memory_req\n",
    "        else:\n",
    "            current_cpu -= cpu_req\n",
    "            current_memory -= memory_req\n",
    "\n",
    "        total_snapshots += 1\n",
    "\n",
    "        #check overcommitment\n",
    "        cpu_overcommit = current_cpu > machine_cpu_capacity if machine_cpu_capacity > 0 else False\n",
    "        memory_overcommit = current_memory > machine_memory_capacity if machine_memory_capacity > 0 else False\n",
    "\n",
    "        if cpu_overcommit or memory_overcommit:\n",
    "            overcommit_count += 1\n",
    "\n",
    "    details = {\n",
    "        'cpu_capacity': machine_cpu_capacity,\n",
    "        'memory_capacity': machine_memory_capacity,\n",
    "        'max_cpu_used': max([0] + [current_cpu for _, _, current_cpu, _ in [(0, 0, 0, 0)]]),\n",
    "        'max_memory_used': max([0] + [current_memory for _, _, _, current_memory in [(0, 0, 0, 0)]])\n",
    "    }\n",
    "\n",
    "    return (machine_id, overcommit_count, total_snapshots, details)\n",
    "\n",
    "print(\"OK\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9019febd-746c-4ee3-8aca-848ae4cb2987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Loading machine events...\n",
      "Active machines: 12486\n",
      "Machine capacities: 12486 machines\n",
      "Machine capacties extracted: 12486 machines\n"
     ]
    }
   ],
   "source": [
    "\n",
    "machine_events_path = \"google-dataset/machine_events/part-*-of-*.csv.gz\"\n",
    "task_events_path = \"google-dataset/task_events/part-*-of-*.csv.gz\"\n",
    "\n",
    "\n",
    "# ========== STEP 1: Machine Capacities ==========\n",
    "print(\"\\n[1] Loading machine events...\")\n",
    "machine_events_raw = sc.textFile(machine_events_path)\n",
    "\n",
    "# Parse and filter\n",
    "parsed_events = machine_events_raw \\\n",
    "    .map(parse_machine_event) \\\n",
    "    .filter(lambda x: x is not None)\n",
    "\n",
    "# group by machine_id\n",
    "grouped_events = parsed_events.groupByKey()\n",
    "\n",
    "#Calculate capacities and filter\n",
    "def process_machine(item):\n",
    "    machine_id, events = item\n",
    "    cpu, mem, is_active = get_latest_machine_capacity(list(events))\n",
    "    if is_active and (cpu > 0 or mem > 0):\n",
    "        return (machine_id, (cpu, mem))\n",
    "    return None\n",
    "\n",
    "machine_events = grouped_events \\\n",
    "    .map(process_machine) \\\n",
    "    .filter(lambda x: x is not None)\n",
    "\n",
    "num_machines = machine_events.count()\n",
    "print(f\"Active machines: {num_machines}\")\n",
    "\n",
    "machine_capacities = machine_events.collectAsMap()\n",
    "print(f\"Machine capacities: {len(machine_capacities)} machines\")\n",
    "\n",
    "bc_machine_capacities = sc.broadcast(machine_capacities)\n",
    "print(f\"Machine capacities extracted: {len(machine_capacities)} machines\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daf86401-d175-4ac7-9408-66e6a65a01ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Loading task events...\n",
      "Task events loaded: 1603148 events\n",
      "\n",
      "[3] Computing task running periods...\n",
      "Task running periods: 500618 periods\n",
      "\n",
      "[4] Analyzing overcommitment...\n",
      "✓ Overcommitment analysis complete\n",
      "\n",
      "[5] Aggregating results...\n",
      "✓ Results aggregated\n",
      "\n",
      "================================================================================\n",
      "RESULTS\n",
      "================================================================================\n",
      "\n",
      "[Machines]\n",
      "  Total analyzed: 12206\n",
      "  With overcommit: 148\n",
      "  Percentage: 1.21%\n",
      "\n",
      "[Time]\n",
      "  Total snapshots: 996044\n",
      "  With overcommit: 2045\n",
      "  Percentage: 0.21%\n",
      "\n",
      "[Top 10 Machines]\n",
      "  1. Machine 1436488167: 68/152 (44.74%)\n",
      "  2. Machine 6201459631: 67/196 (34.18%)\n",
      "  3. Machine 288787745: 58/118 (49.15%)\n",
      "  4. Machine 3422416755: 56/142 (39.44%)\n",
      "  5. Machine 904166: 54/126 (42.86%)\n",
      "  6. Machine 564457288: 51/104 (49.04%)\n",
      "  7. Machine 2787457444: 50/132 (37.88%)\n",
      "  8. Machine 647596483: 46/124 (37.10%)\n",
      "  9. Machine 3676415236: 45/160 (28.12%)\n",
      "  10. Machine 63691529: 43/118 (36.44%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ===== STEP 2: Task Events =====\n",
    "print(\"\\n[2] Loading task events...\")\n",
    "task_events_raw = sc.textFile(task_events_path)\n",
    "\n",
    "task_events = task_events_raw \\\n",
    "    .map(parse_task_event) \\\n",
    "    .filter(lambda x: x is not None)\n",
    "\n",
    "num_task_events = task_events.count()\n",
    "print(f\"Task events loaded: {num_task_events} events\")\n",
    "\n",
    "# ======= STEP 3: Task Running Periods =========\n",
    "print(\"\\n[3] Computing task running periods...\")\n",
    "\n",
    "task_lifecycle = task_events.groupByKey()\n",
    "task_running_periods = task_lifecycle \\\n",
    "    .flatMap(lambda x: compute_task_running_periods(x[0], list(x[1])))\n",
    "\n",
    "num_running_periods = task_running_periods.count()\n",
    "print(f\"Task running periods: {num_running_periods} periods\")\n",
    "\n",
    "# ========= STEP 4: Overcommitment Analysis ==========\n",
    "print(\"\\n[4] Analyzing overcommitment...\")\n",
    "\n",
    "machine_task_periods = task_running_periods \\\n",
    "    .map(lambda x: (x[0], (x[1], x[2], x[3], x[4]))) \\\n",
    "    .filter(lambda x: x[0] is not None)\n",
    "\n",
    "machine_tasks = machine_task_periods.groupByKey().mapValues(list)\n",
    "\n",
    "overcommitment_analysis = machine_tasks \\\n",
    "    .map(lambda x: analyze_machine_overcommitment(x[0], x[1], bc_machine_capacities.value))\n",
    "\n",
    "print(\"Overcommitment analysis complete\")\n",
    "\n",
    "# ======= STEP 5: Aggregate Results ========\n",
    "print(\"\\n[5] Aggregating results...\")\n",
    "\n",
    "results = overcommitment_analysis.collect()\n",
    "\n",
    "total_machines_analyzed = len(results)\n",
    "machines_with_overcommit = sum(1 for _, oc_count, _, _ in results if oc_count > 0)\n",
    "total_snapshots = sum(snapshots for _, _, snapshots, _ in results)\n",
    "total_overcommit_snapshots = sum(oc_count for _, oc_count, _, _ in results)\n",
    "\n",
    "print(\"Results aggregated\")\n",
    "\n",
    "# ======== OUTPUT ========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n[Machines]\")\n",
    "print(f\"  Total analyzed: {total_machines_analyzed}\")\n",
    "print(f\"  With overcommit: {machines_with_overcommit}\")\n",
    "\n",
    "if total_machines_analyzed > 0:\n",
    "    pct_machines = 100.0 * machines_with_overcommit / total_machines_analyzed\n",
    "    print(f\"  Percentage: {pct_machines:.2f}%\")\n",
    "\n",
    "print(f\"\\n[Time]\")\n",
    "print(f\"  Total snapshots: {total_snapshots}\")\n",
    "print(f\"  With overcommit: {total_overcommit_snapshots}\")\n",
    "\n",
    "if total_snapshots > 0:\n",
    "    pct_time = 100.0 * total_overcommit_snapshots / total_snapshots\n",
    "    print(f\"  Percentage: {pct_time:.2f}%\")\n",
    "\n",
    "# top 10 machines\n",
    "if machines_with_overcommit > 0:\n",
    "    print(\"\\n[Top 10 Machines]\")\n",
    "    top_machines = sorted(results, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    for rank, (machine_id, oc_count, total_snaps, details) in enumerate(top_machines, 1):\n",
    "        if oc_count > 0:\n",
    "            pct = 100.0 * oc_count / total_snaps if total_snaps > 0 else 0\n",
    "            print(f\"  {rank}. Machine {machine_id}: {oc_count}/{total_snaps} ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
